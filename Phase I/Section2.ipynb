{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ In\\ the\\ Name\\ of\\ God$\n",
    "## $Probability\\ and\\ Statistics \\ Project $\n",
    "## $Phase1 \\ Section2$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Theory \\ Section\\ 1:$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, Adjacency matrix would be Symmetric with 0 in it's main diagonal. An example would make this crystal clear, Consider:\n",
    "\n",
    "![Alt text](diagram1.png)\n",
    "\n",
    "\n",
    "Intuitively, 3 clusters and 12 people(points) are defined and each cluster's people have nothing in common with people in other clusters. We derive the adjaceny matrix of the indicated graph blindly:\n",
    "\n",
    "\\begin{pmatrix}\n",
    "0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\\\\n",
    "1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\\\\n",
    "1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0  \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0  \\\\\n",
    "0 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\\\\n",
    "0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0  \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1  \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 1 & 1  \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 1 & 1  \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 1  \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 0  \\\\\n",
    "\n",
    "\\end{pmatrix}\n",
    "Since clusters are compeletly separate, it seems that three adjaceny matrix of these separate clusters are connected diagonally to makr a bigger matrix."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Theory \\ Section\\ 2:$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, Adjacency matrix would be Symmetric with 0 in it's main diagonal again. An example would make this crystal clear, Consider:\n",
    "\n",
    "![Alt text](diagram2.png)\n",
    "\n",
    "Intuitively, 3 clusters and 12 people(points) are defined and each cluster's people have Something in common with people in other clusters. We derive the adjaceny matrix of the indicated graph blindly:\n",
    "\n",
    "\\begin{pmatrix}\n",
    "0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0  \\\\\n",
    "1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0  \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0  \\\\\n",
    "1 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 1  \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 1 & 1 & 0 & 0  \\\\\n",
    "0 & 1 & 1 & 1 & 1 & 0 & 1 & 0 & 0  \\\\\n",
    "0 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0  \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 1  \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0  \n",
    "\n",
    "\\end{pmatrix}\n",
    "\n",
    "We observe that the adjaceny matrix is symmetric, But as we expected it is not made by connecting three separate adjaceny matrices."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Theory \\ Section\\ 3:$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "u , v -> People  c -> community(cluster)\n",
    "$\\\\ P(u,v) = 1 - \\Pi_{c\\in M} (1 - P_{c}(u,v))  =  1 - \\Pi_{i}^{M} (1 - P_{i})  $\n",
    "$\\\\ --> P(u,v) = 1 - (1-P_{1})(1-P_{2})...(1-P_{M}) = 1 - \\Pi_{i=1}^{M} (1 - P_{i}) = 1 - A$\n",
    "\n",
    "When two people are members of many special communities , $P_{i} (i\\in M)$ increses , $1 - P_{i} (i\\in M)$ decreases, thus A also decreases and P(u,v) = 1 - A increases accordingly.\n",
    "$\\\\$ Intersection  =>  $P_{i} (i\\in M) \\uparrow$  =>  $1 - P_{i} (i\\in M) \\downarrow$  =>  $1 - \\Pi_{i=1}^{M} (1 - P_{i}) \\uparrow$  =>  $p(u,v) \\uparrow\\\\$\n",
    "Consequently , people's connection get wider as they become members of different particular communities. Intuitively, Being at the intersection of relationships causes more connection between people.\n",
    "Deficiency of this model is mostly due to being an all-or-nothing approach (0 or 1)! (i.e) There is no defined parameter which can describe relativity of people (Having a same taste), so people in a cluster are either connected to each other(1) or not connected to each other(0 - being isolated). However, in a real world having the same taste is relative.(Not 0 or 1) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Theory \\ Section\\ 4:$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\\\ P(u,v) = 1 - \\Pi_{c\\in M} (1 - P_{c}(u,v))  M = {c_{1},c_{2} , .... , c_{n}}\\\\$\n",
    "We khonw that :\n",
    "$ \\\\ P_{c}{u,v} = 1 - e^{-F_{uc}F_{vc}}  =>  P(u,v) = 1 - \\Pi_{c \\in M} (1 - (1 - exp(-F_{uc}F{vc})))$\n",
    "\n",
    "$\\\\ P(u,v) = 1 - \\Pi_{c \\in M} exp(-F_{uc}F_{vc} ) = 1 - exp(\\sum_{c \\in M} F_{uc}F{vc}) $ (Definition of inner product ) \n",
    "$\\\\ \\\\ P(u,v) = 1 - exp(-F_{u}^{T}F_{v}) $\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Theory \\ Section\\ 5:$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the definition of likelehood function, we have:\n",
    "$\\\\P(A|F) = \\Pi_{(u,v) \\in A} p(u,v) \\Pi_{(u,v) \\notin A} (1-p(u,v))  \\\\$\n",
    "Note that in Theory Section 4 we calculated P(u,v) in terms of F matrix elements: \n",
    "$\\\\ \\\\ P(u,v) = 1 - exp(-F_{u}^{T}F_{v}) \\\\$\n",
    "Thus we obtain:\n",
    "$\\\\l(F) = log(P(A|F)) = log( \\Pi_{(u,v) \\in A} p(u,v) \\Pi_{(u,v) \\notin A} (1-p(u,v)) )$ \n",
    "$\\\\= \\sum_{(u,v) \\in A} log(P(u,v)) + \\sum_{u,v) \\notin A} log(1 - P(u,v))$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Theory \\ Section\\ 6:$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From calculus 2, we remember that the gradient of a fenced field is a vector that its components illustrate the changing rate of the field in different directions. The direction of greadient vector field is the the maxmimum changing rate diection ever found. Gradient field's vector shows a path with maximum changing rate(either positive or negative) but after a while, changing rate decreases and the multiple variable function arrives at its extreme point. This issue is so unpleasant! Beacause by following the gradient of a specific F , after some iterations, we can reach the optimized value of F (F* = argmax(l(F))).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](gradient2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Theory \\ Section\\ 7:$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume N(u) is the set of neighbouring points of u:\n",
    "$\\\\ l(F_{u}) = \\sum_{v \\in N(u)} log(1 - e^{(-F_{u}F_{v}^{T})}) - \\sum_{v \\notin N(u)} F_{u}F_{v}^{T} \\\\$ \n",
    "$ \\nabla l(F_{u})= \\sum_{v \\in N(u)} F_{v} \\frac{ exp(-F_{u}F_{v}^{T})}{1 - exp(-F_{u}F_{v}^{T})}  - \\sum_{v \\notin N(u)} F_{v} $\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Simulating \\ Section\\ 1:$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ l(F) = \\sum_{(u,v)\\in A}^{}log(1 - e^{-F_{u}F^{T}_{v}}) - \\sum_{(u,v)\\notin A} F_{u}F^{T}_{v} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def log_likelihood(F, A):\n",
    "    \n",
    "    \n",
    "    B = F.dot(F.T)  #  F . F(Transpose)\n",
    "\n",
    "    neighbouring_part = A*np.log(1.-np.exp(-1.*B)) # matrix multiplication\n",
    "    sum_Neighbours = np.sum(neighbouring_part)\n",
    "    notNeighbouring_part = (1-A)*B # matrix multiplication\n",
    "    sum_notNeighbours = np.sum(notNeighbouring_part)\n",
    "    \n",
    "    \n",
    "    log_likelihoodEstimation = sum_Neighbours - sum_notNeighbours \n",
    "    return log_likelihoodEstimation\n",
    "\n",
    "def gradient(F, A, i):\n",
    "    \n",
    "    rowF, columnF = F.shape\n",
    "\n",
    "    myNeighbours = np.where(A[i])\n",
    "    notNeighbours = np.where(1-A[i])\n",
    "    \n",
    "    sumNeighbours = np.zeros((columnF,))\n",
    "    for neighbor in myNeighbours[0]:\n",
    "        B = F[neighbor].dot(F[i])\n",
    "        sumNeighbours += F[neighbor]*(np.divide(np.exp(-1.*B),1.-np.exp(-1.*B)))\n",
    "\n",
    "\n",
    "    sumNotNeighbour = np.zeros((columnF,))\n",
    "    \n",
    "    for NotNeighbor in notNeighbours[0]:\n",
    "        sumNotNeighbour += F[NotNeighbor]\n",
    "\n",
    "    Gradient = sumNeighbours - sumNotNeighbour\n",
    "    return Gradient\n",
    "\n",
    "\n",
    "\n",
    "def train(A, C, iterations = 100):\n",
    "    # initialize an F\n",
    "    N = A.shape[0]\n",
    "    F = np.random.rand(N,C)\n",
    "\n",
    "    for n in range(iterations):\n",
    "        for person in range(N):\n",
    "            grad = gradient(F, A, person)\n",
    "            F[person] += 0.005*grad                  # updating F   \n",
    "            F[person] = np.maximum(0.001, F[person]) # F should be nonnegative\n",
    "        ll = log_likelihood(F, A)\n",
    "        print('At step %4i logliklihood is %5.4f'%(n,ll))\n",
    "        \n",
    "    return F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Key grid.color: '\"' does not look like a color arg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i):\n\u001b[0;32m     11\u001b[0m         A[i,j]\u001b[39m=\u001b[39mA[j,i]\n\u001b[1;32m---> 13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnx\u001b[39;00m\n\u001b[0;32m     15\u001b[0m plt\u001b[39m.\u001b[39mimshow(A)\n",
      "File \u001b[1;32mc:\\Users\\MATIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py:876\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m config\n\u001b[0;32m    873\u001b[0m \u001b[39m# When constructing the global instances, we need to perform certain updates\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[39m# by explicitly calling the superclass (dict.update, dict.items) to avoid\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m# triggering resolution of _auto_backend_sentinel.\u001b[39;00m\n\u001b[1;32m--> 876\u001b[0m rcParamsDefault \u001b[39m=\u001b[39m _rc_params_in_file(\n\u001b[0;32m    877\u001b[0m     cbook\u001b[39m.\u001b[39;49m_get_data_path(\u001b[39m\"\u001b[39;49m\u001b[39mmatplotlibrc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    878\u001b[0m     \u001b[39m# Strip leading comment.\u001b[39;49;00m\n\u001b[0;32m    879\u001b[0m     transform\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m line: line[\u001b[39m1\u001b[39;49m:] \u001b[39mif\u001b[39;49;00m line\u001b[39m.\u001b[39;49mstartswith(\u001b[39m\"\u001b[39;49m\u001b[39m#\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39melse\u001b[39;49;00m line,\n\u001b[0;32m    880\u001b[0m     fail_on_error\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    881\u001b[0m \u001b[39mdict\u001b[39m\u001b[39m.\u001b[39mupdate(rcParamsDefault, rcsetup\u001b[39m.\u001b[39m_hardcoded_defaults)\n\u001b[0;32m    882\u001b[0m \u001b[39m# Normally, the default matplotlibrc file contains *no* entry for backend (the\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[39m# corresponding line starts with ##, not #; we fill on _auto_backend_sentinel\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[39m# in that case.  However, packagers can set a different default backend\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[39m# (resulting in a normal `#backend: foo` line) in which case we should *not*\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[39m# fill in _auto_backend_sentinel.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MATIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py:810\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m rcsetup\u001b[39m.\u001b[39m_validators:\n\u001b[0;32m    809\u001b[0m     \u001b[39mif\u001b[39;00m fail_on_error:\n\u001b[1;32m--> 810\u001b[0m         config[key] \u001b[39m=\u001b[39m val  \u001b[39m# try to convert to proper type or raise\u001b[39;00m\n\u001b[0;32m    811\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    812\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\MATIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py:646\u001b[0m, in \u001b[0;36mRcParams.__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m    644\u001b[0m         cval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate[key](val)\n\u001b[0;32m    645\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n\u001b[1;32m--> 646\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mve\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    647\u001b[0m     \u001b[39mdict\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, key, cval)\n\u001b[0;32m    648\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: Key grid.color: '\"' does not look like a color arg"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#testing in two small groups\n",
    "A=np.random.rand(40,40)\n",
    "A[0:15,0:25]=A[0:15,0:25]>1- 0.6 # connection prob people with 1 common group\n",
    "A[0:15,25:40]=A[0:15,25:40]>1-0.1 # connection prob people with no common group\n",
    "A[15:40,25:40]=A[15:40,25:40]>1-0.7 # connection prob people with 1 common group\n",
    "A[15:25,15:25]=A[15:25,15:25]>1-0.8 # connection prob people with 2 common group\n",
    "for i in range(40):\n",
    "    A[i,i]=0\n",
    "    for j in range(i):\n",
    "        A[i,j]=A[j,i]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "plt.imshow(A)\n",
    "delta=np.sqrt(-np.log(1-0.1)) # epsilon=0.1\n",
    "F=train(A, 2, iterations = 120)\n",
    "print(F>delta)\n",
    "#G = nx.Digraph(A)\n",
    "\n",
    "\n",
    "G=nx.from_numpy_matrix(A)\n",
    "#G=nx.from_numpy_array(A)\n",
    "C=F>delta # groups members\n",
    "nx.draw(G,node_color=10*(C[:,0])+20*(C[:,1])) ## Because of version of networkx probably\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Theory \\ Section\\ 8:$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective here is to model the connection probability between a pair of nodes based on the similarity in their learned affiliations towards communities. To do this, individual nodes are connected with communities with some number of links, with more links from a node to a community indicating that the node has a higher ‘affilation’ to that group. For a network with N nodes and c communities, the affiliation between nodes and communities is encoded by a matrix, F, where Fuc is the learned count of links (again encoding the affiliation), between node i and community c. Similarly, let Fu and Fv be the community affiliations for nodes u and v. Then the probability that an edge exists between nodes u and v, or P(Auv = 1) is modeled as\n",
    "\n",
    "$ P(A_{uv} = 1) = 1 - exp(-F_{u}F_{v}^{T}) \\\\$\n",
    "The node to community affiliations can be used as a proxy for the total amount of interaction between a pair of nodes u and v with a Poisson distribution. This modeling paradigm will allow for the straightforward modeling of the probability that an edge exists between the node pair. To do this, the total amount of interaction between nodes u and v is modeled as,\n",
    "$  X_{uv}^{(c)} \\sim Poisson(\\lambda = F_{uc}F_{vc}) => X_{uv} = \\sum_{c} X_{uv}^{(c)} \\\\$\n",
    "Note that we also know how the sum of Poisson random variables are distributed:\n",
    "$ X_{uv} \\sim Poisson(\\sum_{c} F_{uc} F_{vc}\\\\$ Thus:\n",
    "\n",
    "$P(X_{uv} > 0) = 1 - P(X_{uv} = 0) = 1 - exp(-\\sum_{c} F_{uc}F_{vc}) \\\\$\n",
    "log-likelihood function and its gradient can be derived similar to Theory section 7:\n",
    "$\\\\ l(F_{u}) = \\sum_{v \\in N(u)} log(1 - e^{(-F_{u}F_{v}^{T})}) - \\sum_{v \\notin N(u)} F_{u}F_{v}^{T} \\\\$ \n",
    "$ \\nabla l(F_{u})= \\sum_{v \\in N(u)} F_{v} \\frac{ exp(-F_{u}F_{v}^{T})}{1 - exp(-F_{u}F_{v}^{T})}  - \\sum_{v \\notin N(u)} F_{v} \\\\ $\n",
    "\n",
    "* Helped by $\\\\$\n",
    "-ADAPTING COMMUNITY DETECTION APPROACHES TO LAGRE,MULTILAYER, AND ATTRIBUTED NETWORKS(Natalie Stanley)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92ddfa334250855030f8ffa053f5bd0b0b206734a5f6d75704f074323b7ac1d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
